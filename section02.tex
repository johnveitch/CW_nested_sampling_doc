\section{Core functions}

Here we will describe the core parts of the code defining the signal model and the probability functions used
for the inference. These assume that the data consists of calibrated narrow-band complex heteroyned time
series'. These time series data streams can be from different detectors, and/or different heterodyne
frequencies. For example you could have a pair times series from both the LIGO Hanford (H1) and LIGO
Livingston (L1) detectors, with one produced with a heterodyne at twice the rotation frequency of a known
pulsar and the other produced with a heterodyne at the rotation frequency.

\subsection{The signal model}

Our code assumes that the rotational phase evolution of a pulsar is defined by the Taylor expansion in phase
\begin{equation}
\phi(t) = 2\pi\left(fT + \frac{1}{2}\dot{f}T^2 + \frac{1}{6}\ddot{f}T^3  \ldots\right)
\end{equation}
where $T$ is the time corrected to an inertial reference frame (the solar system barycentre
for isolated pulsars, or the binary system barycentre for pulsars in binaries), and the $f$'s give
the rotation frequency and its time derivatives. The value of $T = (t+\tau(t)-t_0)$ where $t$ is the
time at a detector, $\tau(t)$ is the time dependent correction to the inertial frame and $t_0$ is the epoch.
In practice the code can currently accept frequency derivatives up to the ninth order. We assume the
calibrated detector data $d(t)$ has been heterodyned such that
\begin{equation}
B'(t) = d(t)e^{-i\Phi_{i,\rm het}(t)},
\end{equation}
where $\Phi_{i,\rm het}(t)$ is the phase evolution for a given data stream $i$, and we produce $B(t)$ by
low-pass filtering and averaging values of $B'(t)$.

Under the standard assumption that the general theory of relativity (GR) is correct the code uses the form of
the signal model defined in \citet{2015arXiv150105832J}, which, when heterodyned and asumming low-pass
filtered, gives a signal at a pulsar's rotation frequency (where $\Phi_{1,{\rm het}}(t) = \phi(t)$) of
\begin{widetext}
\begin{equation}\label{eq:hf}
h_f(t) =  e^{i\Delta\phi_1(t)}\left(-\frac{C_{21}}{4}F_{+}(\psi,t)\sin{\iota}\cos{\iota}e^{i\Phi_{21}^C} +
i\frac{C_{21}}{4}F_{\times}(\psi,t)\sin{\iota}e^{i\Phi_{21}^C} \right)
\end{equation}
and at twice the pulsar's rotation frequency (where $\Phi_{2,{\rm het}}(t) = 2\phi(t)$) of
\begin{equation}\label{eq:h2f}
h_{2f}(t) =  e^{i\Delta\phi_2(t)}\left(-\frac{C_{22}}{2}F_{+}(\psi,t)[1+\cos{}^2\iota]e^{i\Phi_{22}^C} +
iC_{22}F_{\times}(\psi,t)\cos{\iota}e^{i\Phi_{22}^C} \right).
\end{equation}
\end{widetext}
The $F_{+}$ and $F_{\times}$ values are the detector dependent antenna patterns, which are a function of the
detector position, source sky position and source polarisation angle $\psi$. The $C_{21}$, $C_{22}$,
$\Phi_{21}^C$ and $\Phi_{22}^C$ values are convenient ways of representing the waveform in terms of an
amplitude and phase of the signal for the $l=2$, $m=1$ harmonic and $l=m=2$ harmonic respectively. The
$\Delta\phi(t)$ values represent any time dependent phase deviation between the phase used in the heterodyne
and the true signal phase (which does not necessarily have to precisely follow the true rotational phase), so
$\Delta\phi_1(t) = (\phi_{1,{\rm true}}(t)-\Phi_{1,{\rm het}}(t))$ and $\Delta\phi_2(t) = (\phi_{2,{\rm
true}}(t)-\Phi_{2,{\rm het}}(t))$.

To calculate the $\Delta\phi$ values using up to the $(n-1)^{\rm th}$ frequency derivative, and try to avoid numerical overflow issues when dealing with large
phases, the following equation is used
\begin{equation}
\Delta\phi_j(t) = \sum_{k=1}^n \left( \frac{\left(f^{(k-1)}_{j,{\rm true}} - f^{(k-1)}_{j,{\rm het}}\right)}{k!}(t+\delta t_{\rm het})^k + \frac{f^{(k-1)}_{j,{\rm true}}}{k!} \sum_{i=0}^{i<k} \left(\begin{array}{c}k \\ i\end{array} \right) (\delta t_{\rm true}-\delta t_{\rm het})^{k-i} (t+\delta t_{\rm het})^i \right),
\end{equation}
where $f^{(n)}$ is the $n^{\rm th}$ frequency derivative, and $\delta t$ is the combination of any solar system barycentring and binary system
barycentring time delays.

By default the code assumes emission just from the $l=m=2$ mode, i.e.\ there is only a signal at twice the
rotation frequency. In this case $C_{22}$ and $\Phi_{22}^C$ can be related to the more familiar physical
$h_0$ and $\phi_0$ values via $h_0 = 2C_{22}$ and $\phi_0 = \Phi_{22}^C/2$. For the more general case the
relations between the waveform amplitude and phase parameters and physical source parameters are given in
\citet{2015arXiv150105832J}. In general for previous searches we have often assumed that we track the true
signal phase perfectly with the heterodyne and as such $\Delta\phi_i(t) = 0$. In such cases the only time
varying components of the signal are the antenna pattern functions, which allows great speed increases in the
signal generation and likelihood calculations.

\subsection{The likelihood functions}\label{sec:likelihood}

Our code can make use of two different likelihood functions. The default likelihood function is a
Student's {\it t} likelihood function in which it is assumed that the standard deviation of the noise in the
data is unknown, and can therefore be marginalised over. A Gaussian likelihood function can also be used, for
which the code can either take in estimates of the noise standard deviation at each data point, or calculates
these internally based on stationary stretches of data. For the Student's {\it t}-likelihood function, and if
calculated noise standard deviations for the Gaussian likelihood function internally, the code needs to break
up the data into chunks that have (roughly) the same distribution. The method for doing this is given in
Section~\ref{sec:splitting}.

\subsubsection{Student's {\it t}-likelihood}

A full derivative of the Student's {\it t}-likelihood function \citep[see e.g.][]{2005PhRvD..72j2002D} is given
in Appendix~\ref{app:likelihood}, but the final form of the joint likelihood (and its natural logarithm,
which is actually used within the code to maintain precision) for multiple detectors and data streams is
given by
\begin{widetext}
\begin{align}\label{eq:stlikelihood}
p(\mathbf{B}|\vec{\theta}) &= \prod_{i=1}^{N_{\rm dets}} \prod_{j=1}^{N_{\rm s}} \prod_{k=1}^{M_{i,j}}
\frac{(m_{i,j,k}-1)!}{2\pi^{m_{i,j,k}}}
\left(\sum_{n=n_{i,j,0}}^{n_{i,j,0}+(m_{i,j,k}-1)} |B_{i,j,n}-y(\vec{\theta})_{i,j,n}|^2\right)^{-m_{i,j,k}},
\nonumber \\
\ln{p(\mathbf{B}|\vec{\theta})} &= \sum_{i=1}^{N_{\rm dets}} \sum_{j=1}^{N_{\rm s}}
\sum_{k=1}^{M_{i,j}} \left( \mathcal{A}_{i,j,k} - m_{i,j,k}\ln{
\left\{\sum_{n=n_{i,j,0}}^{n_{i,j,0}+(m_{i,j,k}-1)} |B_{i,j,n}-y(\vec{\theta})_{i,j,n}|^2\right\}}
\right),
\end{align}
\end{widetext}
where $N_{\rm dets}$ is the number of detectors used, $N_{\rm s}$ is the number of data streams (e.g.\
heterodyned data from both the rotation frequency and twice the rotation frequency) per detector, $M_{i,j}$ is
the total number of independent data chunks for detector $i$ and data stream $j$ with lengths $m_{i,j,k}$ and
$n_{i,j,0} = \sum_{l=1}^{k} 1+m_{i,j,l-1}$ (with $m_{i,j,0} = 0$) being the index of the first data point in
each chunk. The model $y(\vec{\theta})$ is that given by Eqns.~\ref{eq:hf} and/or \ref{eq:h2f}
depending on which data streams are being analysed. For notational convenience we have made the substitution
$\mathcal{A}_{i,j,k} = \ln{\left([m_{i,j,k}-1]!\right)} - \ln{2} - m_{i,j,k}\ln{\pi}$.

\subsubsection{Gaussian likelihood}

The Gaussian likelihood, and its natural logarithm, are similarly given by
\begin{widetext}
\begin{align}\label{eq:gausslikelihood}
p(\mathbf{B}|\vec{\theta}) &= \prod_{i=1}^{N_{\rm dets}} \prod_{j=1}^{N_{\rm s}} \prod_{k=1}^{L_{i,j}}
\frac{1}{2\pi\sigma_{i,j,k}^2}\exp{\left(-\frac{|B_{i,j,k}-y(\vec{\theta})_{i,j,k}|^2}{2\sigma_{i,j,k}^2}
\right)}, \nonumber \\
\ln{p(\mathbf{B}|\vec{\theta})} &= \sum_{i=1}^{N_{\rm dets}} \sum_{j=1}^{N_{\rm s}}
\sum_{k=1}^{L_{i,j}} \left(\mathcal{B}_{i,j,k} -
\left[\frac{|B_{i,j,k}-y(\vec{\theta})_{i,j,k}|^2}{2\sigma_{i,j,k}^2 } \right] \right)
\end{align}
\end{widetext}
where $L_{i,j}$ is the length of each dataset and $\mathcal{B}_{i,j,k} = -\ln{(2\pi\sigma_{i,j,k}^2)}$. Note
that the normal square root on the normalisation factor is not there because the exponential is already the
product of the real and imaginary data components.

\subsubsection{The null likelihood}

As we will most often want to perform model comparison for the signal model against the data just containing
noise (the null hypothesis in this case) we can define the null likelihoods for both of the above likelihoods
by setting $y(\vec{\theta}) = 0$, so that we have
\begin{align}
\ln{p(\mathbf{B}|y=0)} &= \sum_{i=1}^{N_{\rm dets}} \sum_{j=1}^{N_{\rm s}}
\sum_{k=1}^{M_{i,j}} \Bigg( \mathcal{A}_{i,j,k} - \nonumber \\
&m_{i,j,k}\ln{
\left\{\sum_{n=n_{i,j,0}}^{n_{i,j,0}+(m_{i,j,k}-1)} |B_{i,j,n}|^2\right\}}
\Bigg),
\end{align}
and
\begin{equation}
\ln{p(\mathbf{B}|y=0)} = \sum_{i=1}^{N_{\rm dets}} \sum_{j=1}^{N_{\rm s}}
\sum_{k=1}^{L_{i,j}} \left(\mathcal{B}_{i,j,k} -
\left[\frac{|B_{i,j,k}|^2}{2\sigma_{i,j,k}^2 } \right] \right)
\end{equation}
for the Students-{\it t} and Gaussian likelihoods respectively.

If we were only interested in comparing models calculated using equivalent likelihood functions we could in
general ignore the factors that do not depend on the data or the model, as they would cancel in any odds
ratio. But, in this code we keep them for cases when such a comparison is not performed, e.g.\ if we
want to compared the joint multi-detector likelihood for a signal with the incoherent product of likelihoods
from each detector then we would need these factors to still be present.

\subsubsection{Fast likelihood evaluations}

In cases when the only time varying components of the model are the antenna pattern functions the likelihood
evaluation can be greatly sped-up by pre-calculated the components in the internal summations. For a given sky
position and detector the antenna patterns can be defined by \citep{1998PhRvD..58f3001J}
\begin{align}
F_+(t,\psi) &= \sin{\zeta}\left[a(t)\cos{2\psi} + b(t)\sin{2\psi}\right], \nonumber \\
F_{\times}(t,\psi) &= \sin{\zeta}\left[b(t)\cos{2\psi} - a(t)\sin{2\psi}\right],
\end{align}
where $\psi$ is the \gw polarisation angle, $\zeta$ is the known angle between the detector arms (generally
$90^{\circ}$), and $a(t)$ and $b(t)$ are the time dependent functions for a given detector position and
source sky location that vary over a sidereal day. These functions can be precomputed at a set of times over
a sidereal day and used, via look-up table interpolation, to give the value at any other time (our code
defaults to calculate $a(t)$ and $b(t)$ at 2880 points over a sidereal day). If, for example, we take the
imaginary part of the cross polarisation component of a signal model, then the summation in the likelihood for a
single detector (with $\zeta = 90^{\circ}$), single data stream and single chunk of length $n$ will be given
by
\begin{widetext}
\begin{align}
S =& \sum_{i=1}^n (\Im{(B_i)}-\left[a(t_i)\cos{2\psi} -
b(t_i)\sin{2\psi}\right]\mathcal{C})^2 \nonumber \\
 =& \sum_{i=1}^n \Im{(B_i)}^2 + \mathcal{C}^2\sum_{i=1}^n \left[a(t_i)\cos{2\psi} -
b(t_i)\sin{2\psi}\right]^2 - 2\mathcal{C}\sum_{i=1}^n  \Im{(B_i)}\left[a(t_i)\cos{2\psi} -
b(t_i)\sin{2\psi}\right], \nonumber \\
=& \sum_{i=1}^n \Im{(B_i)}^2 + \mathcal{C}^2\cos{}^2{2\psi}\sum_{i=1}^n a(t_i)^2 +
\mathcal{C}^2\sin{}^2{2\psi}\sum_{i=1}^n b(t_i)^2 - 2\mathcal{C}^2\cos{2\psi}\sin{2\psi}\sum_{i=1}^n
a(t_i)b(t_i) - \nonumber \\
& 2\mathcal{C}\cos{2\psi} \sum_{i=1}^n \Im{(B_i)}a(t_i) + 2\mathcal{C}\sin{2\psi} \sum_{i=1}^n
\Im{(B_i)}b(t_i),
\end{align}
\end{widetext}
where $\mathcal{C}$ represents the imaginary component of waveform amplitude for a given set of parameters.
It can be seen that all the summation terms can be pre-computed. If using the Gaussian likelihood this
pre-computation of the summation terms can also be done, but with the substitutions $B_i \rightarrow
B_i/\sigma_i$, $a(t_i) \rightarrow a(t_i)/\sigma_i$ and $b(t_i) \rightarrow b(t_i)/\sigma_i$. For the model,
assuming GR emission just from the $l=m=2$ mode, it is just the four different $\mathcal{C}$ terms that need
to be calculated during the sampling process within the code.

In the case where we want to search over parameters that mean that $\Delta\phi_i(t) \ne 0$ in the model then
we can not perform this pre-summing. However, {\it reduced order quadrature} methods
\citep[e.g.][]{2014PhRvX...4c1006F, 2015PhRvL.114g1104C} may help in these cases. Such a method is implemented in our
code, but will be discussed in a separate paper.

\subsection{The prior functions}

\subsection{Splitting the data}\label{sec:splitting}

The above likelihood functions require us to have an idea about the timescales on which the data is
stationary, i.e.\ periods when the noise in the data is best described as being drawn from a single
Gaussian distribution. We therefore use a scheme similar to the BayesianBlocks change point algorithm
\citep{1998ApJ...504..405S} to find points at which the statistics of the noise changes.

  
  
  