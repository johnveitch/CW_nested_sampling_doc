\section{Nested sampling setup}

Here we will briefly describe some of the core functions used for the Nested Sampling algorithm within our code. We will
not describe nested sampling itself, over-and-above the very brief summary given in \S{sec:general}, but instead refer
the reader to \citet{Veitch:2010}. We also refer the reader to \citep{2015PhRvD..91d2003V} for a more thorough description
of some of the concepts we will discuss below.

One main point about the nested sampling algorithm is that it starts by randomly drawing a certain number of samples (the number of
which we call the number of live points, $N_{\rm live}$, which will be the constant number of ``active'', or ``live'', samples),  
where a sample is a vector containing a value for each parameter $\vec{\theta}$, from the prior distribution (see \S\ref{sec:priorfuncs}).
The samples must be independent draws. For each of these samples the likeihood will be calculated and the sample $\vec{\theta}_{\rm min}$
corresponding to the minimum likelihood, $L_{\rm min} = p(\mathbf{B}|\vec{\theta}_{\rm min})$, will be noted. As the algorithm
progresses the number of live points stays the
same, but at each iteration a new sample will be added in place of the one with the minimum likelihood, and therefore the
minimum likelihood will continuously be updated to be the minimum value for the current set of points.

\subsection{Proposal functions}

The nested sampling algorithm requires a way to draw new samples from the parameter space that is being explored. The
particular requirement for nested sampling is that any new sample is an independent draw from a constrained version
of prior probabilty function for each parameter. The constraint is that the new sample's likelihood must be greater
than the current value of $L_{\rm min}$, e.g. for a single parameter $x$, the probability of drawing a point at $x_i$ 
would be
\begin{equation}
 p(x=x_i|I)_{\rm constrained} = \begin{cases}
             p(x=x_i|I) & \text{if~} p(\mathbf{B}|x_i) > L_{\rm min}, \\
             0 & \text{otherwise},
            \end{cases}
\end{equation}
where $p(x|I)$ is the prior on $x$.

There are various methods to sample from the constrained prior, the simplest of which is just to samples from the full
prior and only accept a sample if it meets the likelihood constraint. However, such a simple method soon becomes very
inefficient if the likelihood gets more and more tightly concentracted within the prior volume (which can happen rapidly
for high-dimensional problems). One popular nested sampling method is MultiNest \citep{2009MNRAS.398.1601F}, which performs
the sampling by calculating a set of ellipsoids bounding the live points and drawing points uniformly from within them.
Various other approaches exist such as Diffusive Nested Sampling \citet{Brewer2011,2016arXiv160603757B} and POLYCHORD \citet{2015MNRAS.450L..61H}.

The version of nested sampling used in the \lalinf library, as used by our code, makes use of a Markov chain Monte Carlo (MCMC) approach to
drawing new samples \citep{Veitch:2010}. The MCMC attempts to sample from the constrained prior distributions in an efficient manner, with
the final sample of the chain being a statistically independent samples from the rest of the live points. To sample most efficiently
the MCMC requires a proposal distribution that closely resembles the underlying constrain prior that it is trying to sample from.
\lalinf has a variety of potential proposal distributions \citep{2015PhRvD..91d2003V}, but our code currently allows five different
proposals, that can be used in different proportions:
\begin{description}
 \item[Ensemble walk] This is one of the affine invarient ensemble proposals described by \citet{GoodmanWeare}, which adopt the
 scale and shape of the current set of samples. The hard-coded setup in \lalinf is that three samples randomly drawn from a cache
 of samples are used to define the walker samples. This is the main default proposal of our code, and is used as the proposal
 75\% of the time.
 \item[Ensemble stretch] This is another affine invarient ensemble proposal described by \citet{GoodmanWeare}, and makes use of
 two samples randomly drawn from the sample cache. By default this proposal is not used at all.
 \item[Differential evolution] This is similar to the stretch proposal in that it uses two samples randomly drawn from the sample
 cache. By default this proposal is not used at all.
 \item[Uniform proposal] This proposal just draws points from their full prior for parameters that have a uniform prior specified.
 This proposal ise used 25\% of the time by default.
 \item[Frequency jump] This proposal tries jumping between Fourier frequency bins if frequency is one of the required parameters.
 This proposal has not been tested and, by default, is not used at all.
\end{description}
The cache of samples mentioned above, and used by the nested sampling algorithm, is the set of live points, but this cache is
only updated on iterations of the algorithm that are a factor of 10\% of the number of live points.

The length of each MCMC run can be chosen by the user, but by default it is automatically set within the code. To do this,
at the same rate as the cache is updated, the autocorrelation length of the parameters is calculated. A random sample from the current
live points in chosen, and evolved via the MCMC, and the autocorrelation length of each parameter is calculated, $\vec{{\rm acl}}$. The number
of MCMC iterations, $n_{\rm MCMC}$, is then chosen as $n_{\rm MCMC} = {\rm min}({\rm max}(\vec{{\rm acl}}), 5000)$, where 5000 is
a hardcoded maximum length.

\subsubsection{Testing the proposals}

We would like to test whether some of the above proposals lead to accurate calculations of the evidence integral as given in Equation~\ref{eq:evidence}.
It is especially interesting to do this over ranges of prior volumes that are initially similar to the posterior volume, but then diverge to be
much larger than the posterior volume (or in other words, as the information gain, or Kullbackâ€“Leibler divergence, increases). To do this our
code has the option of setting a one-dimensional Gaussian distribution as the likelihood function, and using a flat prior bounded between $A$ and $B$,
and working out the evidence. Analytically the evidence is given by
\begin{align}\label{eq:testgaussev}
 Z &= \int_A^B \frac{1}{\sqrt{2\pi}\sigma}\exp{\left(-\frac{(x-\mu)}{2\sigma^2} \right)}\frac{1}{(B-A)} {\rm d}x, \nonumber \\
   &= \frac{1}{2(B-A)}\left(\erf{\left[\frac{(\mu-A)}{\sqrt{2}\sigma}\right]}-\erf{\left[\frac{(\mu-B)}{\sqrt{2}\sigma}\right]}\right).
\end{align}
As we are often interested in setting upper limits of, for example, the \gw amplitude $h_0$, we can also use the test to see if the
upper limits we obtain from the posterior samples match the expected upper limit obtained (via root finding) from the CDF of the distribution
\begin{equation}\label{eq:testcdf}
 {\rm UL(x)} = \frac{1}{2a}\left(\erf{\left[\frac{(\mu-A)}{\sqrt{2}\sigma}\right]} - \erf{\left[\frac{(\mu-x)}{\sqrt{2}\sigma}\right]}\right),
\end{equation}
where $a = (\erf{\left[(\mu - A)/\sqrt{2}\sigma\right]} - \erf{\left[(\mu - B)/\sqrt{2}\sigma\right]})/2$ is the area under the distribution.
We can calculate the true Kullback-Leibler divergence for via
\begin{align}\label{eq:kldiv}
 D_{\rm KL} =& \int_A^B p(x)\ln{\left(\frac{p(x)}{q(x)}\right)} {\rm d}x, \nonumber \\
 =& \frac{1}{2}\Bigg[\frac{(B-\mu)}{\sqrt{2\pi\sigma^2}}\exp{\left(-\frac{(B-\mu)^2}{2\sigma^2}\right)} - \nonumber \\
 & \erf{\left(\frac{(B-\mu)}{\sqrt{2}\sigma}\right)}\frac{1+2K+\ln{2\pi\sigma^2}}{2} - \nonumber \\
 & \frac{(A-\mu)}{\sqrt{2\pi\sigma^2}}\exp{\left(-\frac{(A-\mu)^2}{2\sigma^2}\right)} + \nonumber \\
 & \erf{\left(\frac{(A-\mu)}{\sqrt{2}\sigma}\right)}\frac{1+2K+\ln{2\pi\sigma^2}}{2}\Bigg],
\end{align}
where $p(x)$ and $q(x)$ are the posterior and prior distributions respectively, and $K = \ln{q(x)} = -\ln{(B-A)}$.
A final thing that we can check, on top of the upper limit value, is whether the posterior samples appear to be drawn from the posterior
distribution. To do this we use a Kolmogorov-Smirnov test comparing the CDF of the samples with the analytical CDF and calculating the
two-sided $p$-value for the null hypothesis that the two distributions are the same.

In the tests below we have run the code on this Gaussian likelihood by with a Gaussian of zero mean and $\sigma = 10^{-24}$, truncated at zero
by fixing the lower prior bound to $A=0$. This is similar to the form of the likelihood seen in pulsar searches when no signal is present.
We have then set a range of upper bounds, $B$ from $10^{-23}$ to $10^{-13}$ increasing by a factor of ten each time, and a range of numbers of
live points from $2^9$ to $2^{13}$ increasing by powers of two each time. For each combination of upper bound and number of live points we have
run the code on the test Gaussian likelihood 100 times to see the statistical spread of the output.

In the first test we check how just using the ensemble walk proposal (which is not the default configuration described above) fairs at
estimating the evidence, upper limit, and posterior distribution. Figure~\ref{fig:walkpropevs} shows a variety of information, but is
primarily shows the distribution of the ratio of evidence output from our code $Z$ to the true evidence calculated via
Equation~\ref{eq:testgaussev} as a function of the value of the upper prior bound $B$ (or equivalently on the top axis the
information gain, in nats, calculated via Equation~\ref{eq:kldiv}). This is shown for the range of different numbers of live points used.
It is clear that as the information gain increases (i.e.\ the posterior is constrained within a successively smaller part of the
prior range) becomes systematically more biased towards overestimating the evidence. It can also be seen that the bias increases with
increasing number of live points. Linear fits (in $\ln{(Z/Z_{\rm true})}$ and $D_{\rm KL}$, the information gain) for different numbers
of live points are shown in Table~\ref{tab:klvsz}. It is interesting to note that the statistical spread of values (if ignoring the
systematic offset) are consistent with the expected range given by the error bars, and calculated using $\sqrt{I/N_{\rm live}}$, where
$I$ is the mean of the {\it information} (in nats) returned by the nested sampling algorithm for each run.

\begin{deluxetable}{l c c}[!h]
\tabletypesize{\footnotesize}
\tablecaption{Linear coefficient in fits of $\ln{(Z/Z_{\rm true})} = mD_{\rm KL} + c$ from the results
shown in Figure~\ref{fig:walkpropevs} for differing numbers of live points.\label{tab:klvsz}}
\tablehead{
\colhead{$N_{\rm live}$} &
\colhead{$c$} &
\colhead{$m$}}
\startdata
512 & $-0.24$ & 0.09 \\
1024 & $-0.20$ & 0.12 \\
2048 & $-0.14$ & 0.13 \\
4096 & $-0.08$ & 0.14 \\
8192 & $-0.04$ & 0.14
\enddata
\end{deluxetable}

Figure~\ref{fig:walkpropuls} shows the distribution of 95\% upper limits on the $x$ parameter in Equation~\ref{eq:testcdf} (calculated by solving
the equation for ${\rm UL}(x) = 0.95$). It can be seen that, other than for the narrowest prior range, there is a systematic bias towards the
upper limit being underestimated by $\sim 2\%$.

The systematic biases in evidence values and upper limits may not be major problem, but does point towards there being some issue with the
implememtation of the ensemble walk proposal.