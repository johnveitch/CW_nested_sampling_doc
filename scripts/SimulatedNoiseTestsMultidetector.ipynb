{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the code on simulated noise for two detectors\n",
    "\n",
    "This notebook provides tests of the `lalapps_pulsar_parameter_estimation_nested` code in comparison to the older `lalapps_pulsar_parameter_estimation` code when running on fake Gaussian noise when using two detectors. The former code uses [nested sampling](https://en.wikipedia.org/wiki/Nested_sampling_algorithm) to sample the likelihood, whilst the latter can either use MCMC sampling of the posterior, or compute the posterior explicitly over a grid of point in the parameter space.\n",
    "\n",
    "To do the comparisons both codes are run such that they divide the data up into \"chunks\" containing 30 points each (or less if required at the end of the data), with the data assumed stationary over those 30 points. However, the `lalapps_pulsar_parameter_estimation_nested` can also be run in a way that allows it to actually calculate the length of stationary data chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import required modules\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import fftconvolve\n",
    "import subprocess as sp\n",
    "import os\n",
    "import sys\n",
    "from time import time\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as pl\n",
    "\n",
    "# these modules require lalapps\n",
    "from lalapps.pulsarpputils import *\n",
    "\n",
    "# some matplotlib configurations\n",
    "mplparams = { \\\n",
    "      'backend': 'Agg',\n",
    "      'text.usetex': True, # use LaTeX for all text\n",
    "      'axes.linewidth': 0.5, # set axes linewidths to 0.5\n",
    "      'axes.grid': True, # add a grid\n",
    "      'grid.linewidth': 0.5,\n",
    "      'font.family': 'sans-serif',\n",
    "      'font.sans-serif': 'Avant Garde, Helvetica, Computer Modern Sans serif',\n",
    "      'font.size': 15 }\n",
    "\n",
    "mpl.rcParams.update(mplparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function to work out how many effective (uncorrelated) samples the MCMC chains contain\n",
    "def indepdendent_samples(d):\n",
    "    # get independent samples from the matrix d, where d contains an MCMC chain over a number of parameters.\n",
    "    # The maximum autocorrelation length of all the parameter is used to define the number of effective samples.\n",
    "    M = 5.\n",
    "    K = 2.\n",
    "\n",
    "    neff = []\n",
    "    for par in d.T:\n",
    "        x = par - np.mean(par)\n",
    "        z = fftconvolve(par, par, 'full')\n",
    "        z = np.fft.ifftshift(z)\n",
    "        acf = z[0:len(par)]\n",
    "        acf = acf/acf[0]\n",
    "\n",
    "        # estimate the autocorrelation length\n",
    "        acf[1:] = acf[1:]*2.\n",
    "        imax = np.floor(len(acf)/K)\n",
    "        cacf = np.cumsum(acf)\n",
    "        s = np.arange(1, len(cacf)+1, dtype=np.float64)/M\n",
    "        idxs = cacf[0:imax] < s[0:imax]\n",
    "        s = s[0:imax]\n",
    "        s = s[idxs]\n",
    "        if len(s) == 0:\n",
    "            acl = 1\n",
    "        else:\n",
    "            acl = s[0]\n",
    "        neff.append(np.floor(len(par)/acl))\n",
    "\n",
    "    minneff = np.min(neff)\n",
    "\n",
    "    return d[np.random.permutation(d.shape[0])[0:minneff],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up the run directories\n",
    "rundir = 'multidetector'\n",
    "if not os.path.isdir(rundir): # make the directory\n",
    "    os.makedirs(rundir)\n",
    "\n",
    "detectors = ['H1', 'L1'] # detectors to use\n",
    "psrname = 'J0000+0000' # a fake pulsar name\n",
    "\n",
    "# set the output directory\n",
    "outdir = os.path.join(rundir, 'output')\n",
    "if not os.path.isdir(outdir):\n",
    "    os.makedirs(outdir)\n",
    "\n",
    "# fake heterodyned data directory (for the lalapps_pulsar_parameter_estimation code\n",
    "# this must be dataDET, where DET is e.g. H1)\n",
    "datadirs = []\n",
    "for detector in detectors:\n",
    "    datadir = os.path.join(rundir, 'data'+detector)\n",
    "    if not os.path.isdir(datadir): # make the directory\n",
    "        os.makedirs(datadir)\n",
    "    datadirs.append(datadir)\n",
    "\n",
    "# set the executables (this assumes that you are using virtual environments with virtualenvwrapper.sh and\n",
    "# have a WORKON_HOME environment variable set, but you can change the path as required)\n",
    "virenv = 'local' # name of your virtual environment\n",
    "execpath = os.path.join(os.environ['WORKON_HOME'], virenv)\n",
    "execpath = os.path.join(execpath, 'bin')\n",
    "\n",
    "ppenexec = os.path.join(execpath, 'lalapps_pulsar_parameter_estimation_nested')\n",
    "n2pexec = os.path.join(execpath, 'lalapps_nest2pos') # script to convert nested samples to posterior samples\n",
    "ppeexec = os.path.join(execpath, 'lalapps_pulsar_parameter_estimation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the codes\n",
    "\n",
    "The code is run on random Gaussian noise with zero mean and a given standard deviation. I output a comparison plot between the posteriors produced for each realisation. I compare the upper limit produced from the nested-sampling-generated posterior and that calculated from the grid-based posterior. I also compare the run times for each implementation of the codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up some general inputs\n",
    "\n",
    "# create a pulsar parameter (TEMPO-stype .par file) file format string\n",
    "pardat = \"\"\"PSRJ J0000+0000\n",
    "RAJ {}\n",
    "DECJ {}\n",
    "F0 123.4567890\n",
    "PEPOCH 56789.0\n",
    "EPHEM DE405\n",
    "\"\"\"\n",
    "\n",
    "# some defaults for the data generation\n",
    "sigma = 1.0e-22        # set data standard deviation\n",
    "dt = 60                # number of seconds between data points\n",
    "gpsstart = 900000000   # GPS start time of data\n",
    "duration = 864000      # duration of data (seconds) - 10 days\n",
    "gpstimes = np.arange(gpsstart, gpsstart+duration, dt) # time stamps\n",
    "dlen = len(gpstimes)   # length of data\n",
    "\n",
    "# get an estimate of the 95% credible upper limit to be expected\n",
    "ulest = 10.8*np.sqrt(sigma**2/dlen)\n",
    "\n",
    "# create the prior file for the lalapps_pulsar_parameter_estimation_nested code\n",
    "# (PHI0 in here is rotational phase, whereas for the older code it is GW phase for trixial emission l=m=2)\n",
    "priorfile = os.path.join(rundir, 'pulsar.prior')\n",
    "priordat = \"\"\"H0 uniform 0 {}\n",
    "PHI0 uniform 0 {}\n",
    "PSI uniform {} {}\n",
    "COSIOTA uniform -1 1\n",
    "\"\"\"\n",
    "fp = open(priorfile, 'w')\n",
    "# set the h0 upper range to be 6 times the expected upper limit \n",
    "fp.write(priordat.format(ulest*6., np.pi, -np.pi/4., np.pi/4.))\n",
    "fp.close()\n",
    "\n",
    "# lalapps_pulsar_parameter_estimation_nested run parameters\n",
    "Nlive = '2048' # number of nested sample live points\n",
    "\n",
    "# lalapps_pulsar_parameter_estimation (MCMC) run parameters\n",
    "iterations = '250000' # number of MCMC iterations after burn-in\n",
    "burnin = '100000'     # number of MCMC iterations for burn-in\n",
    "\n",
    "# lalapps_pulsar_parameter_estimation (grid) run parameters\n",
    "h0steps = '80' # number of grid points for each parameter\n",
    "psisteps = '40'\n",
    "phi0steps = '40'\n",
    "cosiotasteps = '40'\n",
    "h0max = '%.5e' % (6.*ulest) # maximum range of h0 values\n",
    "h0ulc = '95'                # % credible h0 upper limit to output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datafiles = []\n",
    "for i, detector in enumerate(detectors):\n",
    "    # create data\n",
    "    data = sigma*np.random.randn(dlen, 2)\n",
    "\n",
    "    # append times and data together\n",
    "    tad = np.vstack((gpstimes, data.T)).T\n",
    "\n",
    "    # output fake data\n",
    "    datafile = os.path.join(datadirs[i], 'finehet_'+psrname+'_'+detector)\n",
    "    np.savetxt(datafile, tad, fmt='%.6f %.7e %.7e', delimiter='\\t')\n",
    "    datafiles.append(datafile)\n",
    "    \n",
    "# create a random sky position from a uniform distribution on the sky\n",
    "rah, ram, ras = rad_to_hms(2.*np.pi*np.random.rand())\n",
    "decd, decm, decs = rad_to_dms(np.arccos(-1.+2.*np.random.rand()) - np.pi/2.)\n",
    "    \n",
    "# output .par file containing right ascension and declination\n",
    "parfile = os.path.join(rundir, 'pulsar.par')\n",
    "fp = open(parfile, 'w')\n",
    "fp.write(pardat.format(coord_to_string(rah, ram, ras), coord_to_string(decd, decm, decs)))\n",
    "fp.close()\n",
    "    \n",
    "# run lalapps_pulsar_parameter_estimation_nested\n",
    "codecall = ' '.join([ppenexec, '--detectors', ','.join(detectors),\n",
    "                     '--par-file', parfile, '--prior-file', priorfile,\n",
    "                     '--input-files', ','.join(datafiles), '--outfile', os.path.join(outdir, 'fake_nest.txt'),\n",
    "                     '--gzip', '--Nlive', Nlive, '--Nmcmcinitial', '0', '--oldChunks'])\n",
    "t0 = time()\n",
    "p = sp.Popen(codecall, stdout=sp.PIPE, stderr=sp.PIPE, shell=True)\n",
    "out, err = p.communicate()\n",
    "t1 = time()\n",
    "timenested = (t1-t0)\n",
    "    \n",
    "# nested samples need to be converted to posterior samples with lalapps_nest2pos\n",
    "codecall = ' '.join([n2pexec, '--Nlive', Nlive, '-p', os.path.join(outdir, 'fake_post.txt'),\n",
    "                     '-H', os.path.join(outdir, 'fake_nest.txt_params.txt'), '-z',\n",
    "                     os.path.join(outdir, 'fake_nest.txt.gz')])\n",
    "p = sp.Popen(codecall, stdout=sp.PIPE, stderr=sp.PIPE, shell=True)\n",
    "out, err = p.communicate()\n",
    "    \n",
    "# get h0 upper limit from \n",
    "post, evsig, evnoise = pulsar_nest_to_posterior(os.path.join(outdir, 'fake_post.txt.gz'))\n",
    "h0ul = upper_limit_greedy(post['h0'].samples, upperlimit=(float(h0ulc)/100.))\n",
    "    \n",
    "h0ulnested = (h0ul)\n",
    "evratnested = (evsig-evnoise)\n",
    "    \n",
    "# run lalapps_pulsar_parameter_estimation in MCMC mode\n",
    "codecall = ' '.join([ppeexec, '--detectors', ','.join(detectors),\n",
    "                     '--pulsar', psrname, '--par-file', parfile, '--input-dir', rundir,\n",
    "                     '--output-dir', outdir, '--mcmc', '--iterations', iterations,\n",
    "                     '--burn-in', burnin, '--psi-bins', '1000', '--time-bins', '1440'])\n",
    "t0 = time()\n",
    "p = sp.Popen(codecall, stdout=sp.PIPE, stderr=sp.PIPE, shell=True)\n",
    "out, err = p.communicate()\n",
    "t1 = time()\n",
    "timemcmc = (t1-t0)\n",
    "\n",
    "# run lalapps_pulsar_parameter_estimation in grid mode\n",
    "# delete any previously created evidence file as things get appended to it\n",
    "evfile = os.path.join(outdir, 'evidence_%s' % psrname)\n",
    "if os.path.isfile(evfile):\n",
    "    os.remove(evfile)\n",
    "\n",
    "codecall = ' '.join(['lalapps_pulsar_parameter_estimation', '--detectors', ','.join(detectors),\n",
    "                     '--pulsar', psrname, '--par-file', parfile, '--input-dir', rundir,\n",
    "                     '--output-dir', outdir, '--psi-bins', '1000', '--time-bins', '1440',\n",
    "                     '--h0steps', h0steps, '--maxh0', h0max, '--phi0steps', phi0steps,\n",
    "                     '--psisteps', psisteps, '--cisteps', cosiotasteps, '--dob-ul', h0ulc])\n",
    "    \n",
    "t0 = time()\n",
    "p = sp.Popen(codecall, stdout=sp.PIPE, stderr=sp.PIPE, shell=True)\n",
    "out, err = p.communicate()\n",
    "t1 = time()\n",
    "timegrid = (t1-t0)\n",
    "\n",
    "# read in evidence ratio and h0 upper limit produced by grid\n",
    "evfile = os.path.join(outdir, 'evidence_%s' % psrname)\n",
    "# evidence at end of first line, UL at end of second\n",
    "fp = open(evfile, 'r')\n",
    "evlines = fp.readlines()\n",
    "h0ulgrid = float((evlines[1].split())[-1])\n",
    "evratgrid = float((evlines[0].split())[-1])\n",
    "\n",
    "# correct evidence and lalapps_pulsar_parameter_estimation does not apply the h0 and cos(iota) priors\n",
    "# and also account for lalapps_pulsar_parameter_estimation using a 2pi phi0 range rather than pi\n",
    "evratgrid = evratgrid - np.log(6.*ulest) - np.log(2.) + np.log(np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMMENTED OUT FOR SPEED (although this gives identical results to using lalapps_pulsar_parameter_estimation in\n",
    "# its grid-based mode)\n",
    "# use the grid-based python script to double check\n",
    "#datacomp = {detector: data[:,0] + 1j*data[:,1]}\n",
    "#tsdic = {detector: gpstimes}\n",
    "#ra = 0.0\n",
    "#dec = 0.0\n",
    "\n",
    "#paramranges = {'h0': (0., float(h0max), int(h0steps)),\n",
    "#               'psi': (-np.pi/4., np.pi/4., int(psisteps))}\n",
    "\n",
    "#t0 = time()\n",
    "#L, h0pdf, phi0pdf, psipdf, cosiotapdf, lingrid, evrat = pulsar_posterior_grid(detector, tsdic, datacomp, ra, dec, paramranges=paramranges)\n",
    "#t1 = time()\n",
    "\n",
    "#print(\"Python grid-mode took %f s\" % (t1-t0))\n",
    "#print(\"Evidence ratio = %.12e\" % evrat)\n",
    "\n",
    "#pygrid = {'h0': np.vstack((lingrid['h0'], h0pdf)).T,\n",
    "#          'phi': np.vstack((lingrid['phi0'], phi0pdf)).T,\n",
    "#          'psi': np.vstack((lingrid['psi'], psipdf)).T,\n",
    "#          'ciota': np.vstack((lingrid['cosiota'], cosiotapdf)).T}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, axarr = pl.subplots(2, 2, figsize=(8,8))\n",
    "\n",
    "# lalapps_pulsar_parameter_estimation_nested posterior samples\n",
    "postppen = np.loadtxt(os.path.join(outdir, 'fake_post.txt.gz'), skiprows=1)\n",
    "ppenidxs = {'h0': 1, 'phi': 2, 'ciota': 0, 'psi': 3}\n",
    "postppemcmc = np.loadtxt(os.path.join(outdir, 'MCMCchain_%s_%s' % (psrname, detector)), comments='%')\n",
    "\n",
    "# get independent MCMC samples\n",
    "postmcmcind = indepdendent_samples(postppemcmc[:,1:])\n",
    "ppemcmcidxs = {'h0': 0, 'phi': 1, 'ciota': 2, 'psi': 3}\n",
    "print(\"Number of independent MCMC samples is %d from %s\" % (postmcmcind.shape[0], postppemcmc.shape[0]))\n",
    "\n",
    "xlabels = {'h0': '$h_0$', 'phi': '$\\phi_0$ (rads)', 'ciota': '$\\cos{\\iota}$', 'psi': '$\\psi$ (rads)'}\n",
    "ylabels = {'h0': '$p(h_0|d,I)$', 'phi': '$p(\\phi_0|d,I)$ (rads)', 'ciota': '$p(\\cos{\\iota}|d,I)$', 'psi': '$p(\\psi|d,I)$ (rads)'}\n",
    "\n",
    "arr = {'h0': axarr[0, 0], 'phi': axarr[0,1], 'ciota': axarr[1,0], 'psi': axarr[1,1]}\n",
    "lims = {'h0': [0., None], 'phi': [0., 2.*np.pi], 'ciota': [-1., 1.], 'psi': [-np.pi/4., np.pi/4.]}\n",
    "for par in ['h0', 'phi', 'psi', 'ciota']:\n",
    "    parscale = 1.\n",
    "    if par == 'phi': # for the nested sampling output scale PHI0 by two to make it GW phase rather than rotational phase\n",
    "        parscale = 2.\n",
    "\n",
    "    gridpdf = np.loadtxt(os.path.join(outdir, 'pdf_%s.%s.%s' % (par, psrname, detector)))\n",
    "\n",
    "    arr[par].plot(gridpdf[:,0], gridpdf[:,1], 'b', linewidth=1.5)\n",
    "    #arr[par].plot(pygrid[par][:,0]*parscale, pygrid[par][:,1]/parscale, 'g--', linewidth=1.5)\n",
    "\n",
    "    arr[par].hist(postmcmcind[:,ppemcmcidxs[par]], bins=20, normed=True, color='r', linewidth=1.5, histtype='step')\n",
    "    arr[par].hist(postppen[:,ppenidxs[par]]*parscale, bins=20, normed=True, color='k', linewidth=1.5, histtype='step')\n",
    "\n",
    "    arr[par].set_xlabel(xlabels[par])\n",
    "    arr[par].set_ylabel(ylabels[par])\n",
    "\n",
    "    if par == 'h0':\n",
    "        #arr[par].legend(['grid 1', 'grid 2', 'MCMC', 'Nest'], loc=1)\n",
    "        arr[par].legend(['grid', 'MCMC', 'Nest'], loc=1)\n",
    "        xmin, xmax = arr[par].get_xlim()\n",
    "        arr[par].set_xlim([lims[par][0], xmax])\n",
    "    else:\n",
    "        arr[par].set_xlim(lims[par])\n",
    "\n",
    "pl.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Difference in upper limits:\")\n",
    "print(\"h0 upper limit (nested) = %.2e\" % h0ulnested)\n",
    "print(\"h0 upper limit (grid) = %.2e\" % h0ulgrid)\n",
    "print(\"percentage difference = %.2f\" % (100.*np.abs(h0ulnested-h0ulgrid)/h0ulnested))\n",
    "print(\"\\n\")\n",
    "print(\"Difference in evidence ratios:\")\n",
    "print(\"log(evidence ratio) (nested) = %.2e\" % evratnested)\n",
    "print(\"log(evidence ratio) (grid) = %.2e\" % evratgrid)\n",
    "print(\"absolute difference = %.2f\" % (np.abs(evratnested-evratgrid)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
